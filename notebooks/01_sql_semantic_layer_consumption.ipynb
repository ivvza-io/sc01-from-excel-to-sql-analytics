{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Semantic Layer Consumption Example\n",
        "\n",
        "**Purpose:** Demonstrate how the SQL semantic layer enables reproducible analytical consumption with minimal data wrangling.\n",
        "\n",
        "## What This Notebook Does\n",
        "- Load semantic views (from CSV or PostgreSQL)\n",
        "- Build analysis-ready dataset at heat level\n",
        "- Validate grain and data quality\n",
        "- Show two simple consumption examples\n",
        "\n",
        "## What This Notebook Does NOT Do\n",
        "- SPC or control charts → SC02+\n",
        "- Root-cause analysis → SC02+\n",
        "- Statistical modeling → SC02+\n",
        "- Deep domain analysis\n",
        "\n",
        "**Key Insight:** The simplicity is intentional. Complexity is handled upstream in the data model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 0: Setup & Configuration\n",
        "\n",
        "Choose your data source:\n",
        "- **CSV** (default): No dependencies, works offline\n",
        "- **PostgreSQL**: See SQL queries in action, requires DB running\n",
        "\n",
        "Both return data in the same format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7df3f285",
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sqlalchemy'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msqlalchemy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_engine, text\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m     10\u001b[39m sys.path.insert(\u001b[32m0\u001b[39m, \u001b[38;5;28mstr\u001b[39m(Path.cwd().parent / \u001b[33m'\u001b[39m\u001b[33msrc\u001b[39m\u001b[33m'\u001b[39m))\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sqlalchemy'"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sqlalchemy import create_engine, text\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
        "\n",
        "from loaders import load_semantic_views, resolve_repo_root, load_database_url\n",
        "from plots import plot_uts_histogram, plot_uts_boxplot\n",
        "\n",
        "plt.style.use('ggplot')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e7586ba",
      "metadata": {},
      "source": [
        "## Section 1: Load Semantic Views\n",
        "\n",
        "Load three semantic views:\n",
        "1. `v_heats_by_alloy`: 1 row per heat (alloy assignment)\n",
        "2. `v_heats_by_final_product`: 1 row per heat (product metadata)\n",
        "3. `v_lab_values_by_heats`: multiple rows per heat (lab results)\n",
        "4. `v_analysis_dataset` : analysis ready view for comparsion with df built qith pandas\n",
        "\n",
        "The same code works for both CSV and PostgreSQL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a26ff9e",
      "metadata": {},
      "outputs": [],
      "source": [
        "repo_root = resolve_repo_root()\n",
        "database_url = load_database_url(repo_root)\n",
        "DATA_SOURCE = 'postgresql'\n",
        "\n",
        "loaded = load_semantic_views(\n",
        "    data_source=DATA_SOURCE,\n",
        "    repo_root=repo_root,\n",
        "    database_url=database_url\n",
        ")\n",
        "\n",
        "df_heats_alloy = loaded['df_heats_alloy']\n",
        "df_final_prod = loaded['df_final_prod']\n",
        "df_lab = loaded['df_lab']\n",
        "df_sql = loaded['df_sql']\n",
        "\n",
        "print('✓ Loaded semantic views:\\n')\n",
        "print(f'  - source: {loaded['data_source']}')\n",
        "print(f'  - v_heats_by_alloy: {len(df_heats_alloy)} rows')\n",
        "print(f'  - v_final_product: {len(df_final_prod)} rows')\n",
        "print(f'  - v_lab_values: {len(df_lab)} rows')\n",
        "print(f'  - v_lab_values: {len(df_sql)} rows\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "194dc4a8",
      "metadata": {},
      "source": [
        "## Section 2: Grain Validation\n",
        "\n",
        "**Critical:** Verify the semantic layer respects heat-level grain contracts.\n",
        "\n",
        "Expected grain:\n",
        "- `v_heats_by_alloy`: 1 row per heat\n",
        "- `v_final_product`: 1 row per heat\n",
        "- `v_lab_values`: 1 row per (heat, test_name, session_type)\n",
        "\n",
        "This prevents silent errors in joins."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7471db8b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 2: Grain Validation\n",
        "# ============================================================================\n",
        "\n",
        "print('\\n' + '=' * 80)\n",
        "print('GRAIN VALIDATION (Core to SC01)')\n",
        "print('=' * 80 + '\\n')\n",
        "\n",
        "# Validate v_heats_by_alloy\n",
        "grain_alloy = df_heats_alloy.groupby('heat_id').size()\n",
        "assert grain_alloy.max() == 1, 'ERROR: Duplicates in v_heats_by_alloy'\n",
        "print(f'✓ v_heats_by_alloy: 1 row per heat ({len(df_heats_alloy)} heats)')\n",
        "\n",
        "# Validate v_final_product\n",
        "grain_product = df_final_prod.groupby('heat_id').size()\n",
        "assert grain_product.max() == 1, 'ERROR: Duplicates in v_final_product'\n",
        "print(f'✓ v_final_product: 1 row per heat ({len(df_final_prod)} heats)')\n",
        "\n",
        "# Validate v_lab_values\n",
        "lab_key = df_lab.groupby(['heat_id', 'test_name']).size()\n",
        "assert lab_key.max() == 1, 'ERROR: Duplicates in v_lab_values'\n",
        "print(f'✓ v_lab_values: No duplicates within (heat, test, session)')\n",
        "\n",
        "# Check alignment\n",
        "common_heats = set(df_heats_alloy['heat_id']) & set(df_final_prod['heat_id'])\n",
        "print(f'\\n✓ {len(common_heats)} heats in both alloy and product views')\n",
        "print('\\n✓ GRAIN CONTRACTS VALIDATED')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e47c01f5",
      "metadata": {},
      "source": [
        "## Section 3: Build Analysis-Ready Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef57d770",
      "metadata": {},
      "source": [
        "### Two Approaches to the Same Result\n",
        "\n",
        "In this section, we demonstrate the core value proposition of a semantic layer:\n",
        "\n",
        "**Approach 1 (Pandas):** Explicitly construct the analysis dataset by pivoting lab values and joining semantic views. This shows the *logic* behind data construction—each step is visible and debuggable.\n",
        "\n",
        "**Approach 2 (SQL View):** Load pre-built dataset directly from `v_analysis_dataset` view. This demonstrates the *efficiency* gain: the analyst writes one line of SQL instead of multiple pandas operations.\n",
        "\n",
        "### Why This Matters\n",
        "\n",
        "With a well-designed semantic layer:\n",
        "- **Reduced complexity:** Analysts work with curated views, not raw tables\n",
        "- **Formal data contracts:** Grain, column names, and transformations are standardized\n",
        "- **Less boilerplate:** No need to rewrite pivot/join logic across projects\n",
        "- **Single source of truth:** Data definition lives in database, not notebooks\n",
        "\n",
        "The comparison in **Section 3B** validates that both approaches produce identical results, proving the semantic layer abstraction is correct and trustworthy."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba940207",
      "metadata": {},
      "source": [
        "**Approach 1 - Pandas:**\n",
        "\n",
        "Create 1 row per heat by:\n",
        "1. Pivoting lab results (test_name → columns)\n",
        "2. Inner join on heat_id\n",
        "\n",
        "This replaces multi-file spreadsheet merges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c819490f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 3: Build Analysis-Ready Dataset\n",
        "# ============================================================================\n",
        "\n",
        "print('\\n' + '=' * 80)\n",
        "print('BUILDING ANALYSIS-READY DATASET')\n",
        "print('=' * 80 + '\\n')\n",
        "\n",
        "# Pivot lab results wide\n",
        "lab_wide = (\n",
        "    df_lab.pivot_table(\n",
        "        index='heat_id',\n",
        "        columns='test_name',\n",
        "        values='test_value',\n",
        "        aggfunc='mean'\n",
        "    )\n",
        "    .rename(columns={\n",
        "        'UTS_MPa': 'uts_value',\n",
        "        'YS_MPa': 'ys_value',\n",
        "        'EL_percent': 'elongation_value',\n",
        "        'Thickness measurement': 'thickness_mm'\n",
        "    })\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "print(f'Pivoted lab data: {len(lab_wide)} heats with lab results')\n",
        "\n",
        "# Join alloy + product + lab\n",
        "df = (\n",
        "    df_heats_alloy\n",
        "    .merge(df_final_prod, on=['heat_id','heat_num','alloy_code'])\n",
        "    .merge(lab_wide, on='heat_id')\n",
        ")\n",
        "\n",
        "# Select columns\n",
        "df = df[[\n",
        "    'heat_id', 'alloy_code', 'product_type', 'base_temper', 'h_level','spec_thickness',\n",
        "    'uts_value', 'ys_value', 'elongation_value'\n",
        "]]\n",
        "\n",
        "print(f'\\nFinal dataset: {len(df)} heats, {len(df.columns)} features')\n",
        "print(f'Grain: 1 row per heat (validated)')\n",
        "print(f'\\nFirst 5 rows:')\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f6f8c96",
      "metadata": {},
      "source": [
        "\n",
        "**SQL: `v_analysis_dataset`:**\n",
        "- Single query with LEFT JOINs\n",
        "- Subqueries for each test type (UTS, YS, elongation)\n",
        "- Same result: 1 row per heat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bde2f5e",
      "metadata": {},
      "outputs": [],
      "source": [
        "display(df_sql.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "814061b2",
      "metadata": {},
      "source": [
        "## Section 3B: Pandas vs SQL - Comparing Approaches\n",
        "\n",
        "### Why Compare?\n",
        "\n",
        "Both Pandas and SQL can build the same analysis dataset. Comparing them validates:\n",
        "- Pandas transformations are correct\n",
        "- SQL view logic is equivalent\n",
        "- Results are reproducible in either approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2735612",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparison: Pandas vs SQL Approach\n",
        "print('\\n' + '=' * 80)\n",
        "print('COMPARISON: Pandas vs SQL Approach')\n",
        "print('=' * 80 + '\\n')\n",
        "\n",
        "if df_sql is not None:  # PostgreSQL mode\n",
        "    # Sort both datasets by heat_id for comparison\n",
        "    df_sql_sorted = df_sql.sort_values('heat_id').reset_index(drop=True)\n",
        "    df_pandas_sorted = df.sort_values('heat_id').reset_index(drop=True)\n",
        "    \n",
        "    # Find common columns\n",
        "    common_cols = list(set(df_sql_sorted.columns) & set(df_pandas_sorted.columns))\n",
        "    \n",
        "    # Compare\n",
        "    if df_sql_sorted[common_cols].equals(df_pandas_sorted[common_cols]):\n",
        "        print('✓ Pandas and SQL produce IDENTICAL results')\n",
        "        print(f'  Pandas approach: {len(df)} heats, {len(df.columns)} features')\n",
        "        print(f'  SQL approach: {len(df_sql)} heats, {len(df_sql.columns)} features')\n",
        "    else:\n",
        "        print('✗ WARNING: Results differ!')\n",
        "else:\n",
        "    print('(Skipped: CSV mode, no SQL comparison available)')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bd17d62",
      "metadata": {},
      "source": [
        "## Section 4: Example Analysis #1 - Simple Segmentation\n",
        "\n",
        "Filter → GroupBy → Aggregate\n",
        "\n",
        "This is a common consumption pattern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0962daf5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 4: Example Analysis #1 - Simple Segmentation\n",
        "# ============================================================================\n",
        "\n",
        "print('\\n' + '=' * 80)\n",
        "print('EXAMPLE ANALYSIS #1: SIMPLE SEGMENTATION')\n",
        "print('=' * 80 + '\\n')\n",
        "\n",
        "# Define segment\n",
        "segment = df[\n",
        "    (df.product_type == 'circle') &\n",
        "    (df.base_temper == 'O') &\n",
        "    (df.spec_thickness.between(0.80, 1.20))\n",
        "].copy()\n",
        "\n",
        "print(f'Segment: product=\"circle\", temper=\"O\", thickness 0.80-1.20 mm')\n",
        "print(f'Result: {len(segment)} heats\\n')\n",
        "\n",
        "# Aggregate by alloy\n",
        "summary = (\n",
        "    segment\n",
        "    .groupby(['alloy_code'], as_index=False)\n",
        "    .agg(\n",
        "        n=('heat_id', 'size'),\n",
        "        avg_uts=('uts_value', 'mean'),\n",
        "        sd_uts=('uts_value', 'std'),\n",
        "        avg_ys=('ys_value', 'mean'),\n",
        "    )\n",
        "    .round({'avg_uts': 1, 'sd_uts': 1, 'avg_ys': 1})\n",
        "    .sort_values('n', ascending=False)\n",
        ")\n",
        "\n",
        "print('Summary by alloy (reusable for reporting):')\n",
        "display(summary)\n",
        "print('\\nInsight: UTS varies by alloy; consistency within each alloy is stable')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeb41e57",
      "metadata": {},
      "source": [
        "## Section 5: Example Analysis #2 - Quick Visualization\n",
        "\n",
        "Two simple charts to validate data quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22d56bb3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 5: Example Analysis #2 - Quick Visualization\n",
        "# ============================================================================\n",
        "\n",
        "print('\\n' + '=' * 80)\n",
        "print('EXAMPLE ANALYSIS #2: QUICK VISUALIZATION')\n",
        "print('=' * 80 + '\\n')\n",
        "\n",
        "ALLOY = '3004'\n",
        "# single_alloy = segment[segment['alloy_code'] == ALLOY]\n",
        "SEGMENT_TITLE = 'O-temper circles, 0.80-1.20 mm'\n",
        "\n",
        "\n",
        "fig, ax = plot_uts_histogram(segment,'ys_value',alloy = ALLOY,segment_name=SEGMENT_TITLE)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc226da1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Boxplot: Compare across alloys\n",
        "print('\\nBoxplot: UTS distribution by alloy (same segment)\\n')\n",
        "\n",
        "fig, ax = plot_uts_boxplot( \n",
        "    segment,\n",
        "    group_col='alloy_code',\n",
        "    metric_col = 'uts_value',\n",
        "    segment_name=SEGMENT_TITLE)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47933397",
      "metadata": {},
      "source": [
        "## Section 6: Sanity Checks\n",
        "\n",
        "Quick validation that the dataset is complete and within expected ranges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a611b189",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 6: Sanity Checks\n",
        "# ============================================================================\n",
        "\n",
        "print('\\n' + '=' * 80)\n",
        "print('SANITY CHECKS')\n",
        "print('=' * 80 + '\\n')\n",
        "\n",
        "print('Data completeness:')\n",
        "print(f'  Total heats: {len(df)}')\n",
        "print(f'  Missing UTS: {df['uts_value'].isna().sum()}')\n",
        "print(f'  Missing YS: {df['ys_value'].isna().sum()}')\n",
        "print(f'  Missing YS: {df['elongation_value'].isna().sum()}')\n",
        "\n",
        "print('\\nAlloy distribution:')\n",
        "print(df['alloy_code'].value_counts().sort_index())\n",
        "\n",
        "print('\\nTemper distribution:')\n",
        "print(df['base_temper'].value_counts().sort_index())\n",
        "\n",
        "print('\\nUTS statistics:')\n",
        "print(f'  Range: {df['uts_value'].min():.1f} - {df['uts_value'].max():.1f} MPa')\n",
        "print(f'  Mean ± Std: {df['uts_value'].mean():.1f} ± {df['uts_value'].std():.1f} MPa')\n",
        "\n",
        "print('\\n✓ Dataset complete and within expected ranges')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 7: Closing Notes\n",
        "\n",
        "### What This Demonstrated\n",
        "\n",
        "1. **Semantic layer as analytical interface:** Simple joins using `heat_id`\n",
        "2. **Grain validation:** Heat-level contracts are explicit\n",
        "3. **Analysis-ready dataset:** Built in 3 lines (pivot + 2 merges)\n",
        "4. **Reproducible consumption:** CSV or PostgreSQL, same result\n",
        "\n",
        "### Key Insight\n",
        "\n",
        "**The semantic layer abstracts away data origin.** Analyst doesn't care whether data comes from CSV or live database. The interface is the same.\n",
        "\n",
        "### Why This Matters for SC01\n",
        "\n",
        "- Data quality is enforced upstream (not downstream)\n",
        "- Analyses are comparable because semantics are stable\n",
        "- Reproducibility is guaranteed because grain contracts are explicit\n",
        "- Downstream analyses (SC02-SC05) can trust the foundation\n",
        "\n",
        "### What Comes Next\n",
        "\n",
        "- **SC02:** Does chemistry contain predictive signal for UTS?\n",
        "- **SC03:** Do models generalize across alloy systems?\n",
        "- **SC04:** Do process variables improve robustness?\n",
        "- **SC05:** How do we translate models into decision tools?\n",
        "\n",
        "All downstream studies use this same semantic layer, ensuring consistent, defensible analysis."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
